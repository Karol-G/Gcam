{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "ROOT_DIR = \"data/tumor_seg_data\"\n",
    "TRANSFORM = False\n",
    "DEBUG = False\n",
    "\n",
    "class TumorDataset(Dataset):\n",
    "    \"\"\" Returns a TumorDataset class object which represents our tumor dataset.\n",
    "    TumorDataset inherits from torch.utils.data.Dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        \"\"\" Constructor for our TumorDataset class.\n",
    "        Parameters:\n",
    "            root_dir(str): Directory with all the images.\n",
    "            transform(bool): Flag to apply image random transformation.\n",
    "            DEBUG(bool): To switch to debug mode for image transformation.\n",
    "\n",
    "        Returns: None\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.root_dir = ROOT_DIR\n",
    "        self.transform = {'hflip': TF.hflip,\n",
    "                          'vflip': TF.vflip,\n",
    "                          'rotate': TF.rotate}\n",
    "        self.default_transformation = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((512, 512))\n",
    "        ])\n",
    "        self.DEBUG = DEBUG\n",
    "        if not TRANSFORM:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Overridden method from inheritted class to support\n",
    "        indexing of dataset such that datset[I] can be used\n",
    "        to get Ith sample.\n",
    "        Parameters:\n",
    "            index(int): Index of the dataset sample\n",
    "\n",
    "        Return:\n",
    "            sample(dict): Contains the index, image, mask torch.Tensor.\n",
    "                        'index': Index of the image.\n",
    "                        'image': Contains the tumor image torch.Tensor.\n",
    "                        'mask' : Contains the mask image torch.Tensor.\n",
    "        \"\"\"\n",
    "        index += 3000\n",
    "        image_name = os.path.join(self.root_dir, str(index)+'.png')\n",
    "        mask_name = os.path.join(self.root_dir, str(index)+'_mask.png')\n",
    "\n",
    "        image = Image.open(image_name)\n",
    "        mask = Image.open(mask_name)\n",
    "\n",
    "        image = self.default_transformation(image)\n",
    "        mask = self.default_transformation(mask)\n",
    "\n",
    "        # Custom transformations\n",
    "        if self.transform:\n",
    "            image, mask = self._random_transform(image, mask)\n",
    "\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        #mask = TF.to_tensor(mask).squeeze()\n",
    "\n",
    "        image = image.to(self.device)\n",
    "        sample = {\"img\": image, \"gt\": mask, \"filepath\": image_name}\n",
    "        return sample\n",
    "\n",
    "    def _random_transform(self, image, mask):\n",
    "        \"\"\" Applies a set of transformation in random order.\n",
    "        Each transformation has a probability of 0.5\n",
    "        \"\"\"\n",
    "        choice_list = list(self.transform)\n",
    "        for _ in range(len(choice_list)):\n",
    "            choice_key = random.choice(choice_list)\n",
    "            if self.DEBUG:\n",
    "                print(f'Transform choose: {choice_key}')\n",
    "            action_prob = random.randint(0, 1)\n",
    "            if action_prob >= 0.5:\n",
    "                if self.DEBUG:\n",
    "                    print(f'\\tApplying transformation: {choice_key}')\n",
    "                if choice_key == 'rotate':\n",
    "                    rotation = random.randint(15, 75)\n",
    "                    if self.DEBUG:\n",
    "                        print(f'\\t\\tRotation by: {rotation}')\n",
    "                    image = self.transform[choice_key](image, rotation)\n",
    "                    mask = self.transform[choice_key](mask, rotation)\n",
    "                else:\n",
    "                    image = self.transform[choice_key](image)\n",
    "                    mask = self.transform[choice_key](mask)\n",
    "            choice_list.remove(choice_key)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Overridden method from inheritted class so that\n",
    "        len(self) returns the size of the dataset.\n",
    "        \"\"\"\n",
    "        error_msg = 'Part of dataset is missing!\\nNumber of tumor and mask images are not same.'\n",
    "        total_files = len(os.listdir(self.root_dir))\n",
    "\n",
    "        assert (total_files % 2 == 0), error_msg\n",
    "        return total_files//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from models.tumor_seg.bts.model import DynamicUNet\n",
    "\n",
    "FILTER_LIST = [16,32,64,128,256]\n",
    "MODEL_NAME = f\"UNet-{FILTER_LIST}.pt\"\n",
    "STATE_DICT_PATH = 'models/tumor_seg/saved_models/'\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "class TumorSegModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super(TumorSegModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.model = DynamicUNet(FILTER_LIST).to(self.device)\n",
    "        self.restore_model(os.path.join(STATE_DICT_PATH, MODEL_NAME))\n",
    "        self.model.eval()\n",
    "\n",
    "    def restore_model(self, path):\n",
    "        \"\"\" Loads the saved model and restores it to the \"model\" object.\n",
    "        Loads the model based on device used for computation.(CPU/GPU)\n",
    "        Follows the best method recommended by Pytorch\n",
    "        Link: https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended\n",
    "        Parameters:\n",
    "            path(str): The file location where the model is saved.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if self.device == 'cpu':\n",
    "            self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
    "        else:\n",
    "            self.model.load_state_dict(torch.load(path))\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        self.output = self.model(batch)\n",
    "        self.mask = (self.output > THRESHOLD)\n",
    "        self.output = self.output * self.mask\n",
    "        self.output[self.output != 0] = 1\n",
    "\n",
    "        output_numpy = self.output.detach().cpu().numpy()\n",
    "        self.classes, self.is_ok = [], []\n",
    "        for x in output_numpy:\n",
    "            nonzero = np.count_nonzero(x)\n",
    "            if nonzero > 0:\n",
    "                self.classes.append([\"tumor\"])\n",
    "                self.is_ok.append(True)\n",
    "            else:\n",
    "                self.classes.append([\"no_tumor\"])\n",
    "                self.is_ok.append(False)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "\n",
    "    def is_backward_ready(self):\n",
    "        return True\n",
    "\n",
    "    def get_mask(self):\n",
    "        return self.mask\n",
    "\n",
    "    def get_ok_list(self):\n",
    "        return self.is_ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"\n",
    "dataset = TumorDataset(device=DEVICE)\n",
    "model = TumorSegModel(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate_grad_cam\n",
    "\n",
    "evaluate_grad_cam.evaluate_dataset(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dismissed the last 28 module layers (Note: This number can be inflated if the model contains many nested module layers)\n",
      "Selected module layer: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1faa6d96d08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import run_grad_cam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_GCAM, image_GGCAM = run_grad_cam.run(model, dataset.__getitem__(0))\n",
    "\n",
    "plt.imshow(image_GCAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}