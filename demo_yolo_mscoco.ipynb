{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import compress\n",
    "from models.yolo.models import Darknet\n",
    "from models.yolo.utils.utils import non_max_suppression, load_classes\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "MODEL_DEF = \"models/yolo/config/yolov3.cfg\"\n",
    "WEIGHTS_PATH = \"models/yolo/weights/yolov3.weights\"\n",
    "CLASS_PATH = \"models/yolo/data/coco.names\"\n",
    "CONF_THRES = 0.8\n",
    "NMS_THRES = 0.4\n",
    "IMG_SIZE = 416\n",
    "CATEGORY_NAME = 'person'\n",
    "\n",
    "class YoloModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super(YoloModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.model = Darknet(MODEL_DEF, img_size=IMG_SIZE).to(self.device)\n",
    "        self.model.load_darknet_weights(WEIGHTS_PATH)\n",
    "        self.model.eval()\n",
    "        self.classes = load_classes(CLASS_PATH)\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        detections = self.model(batch)\n",
    "        detections = non_max_suppression(detections, CONF_THRES, NMS_THRES)\n",
    "        self.ids, self._probs, self.probs, self.pred_classes, self.is_ok = [], [], [], [], []\n",
    "\n",
    "        for det in detections:\n",
    "            if det is None:\n",
    "                self._save_results(False, [], [], [])\n",
    "                continue\n",
    "            ids, probs, pred_classes = self._extract_results(det)\n",
    "            if not CATEGORY_NAME in pred_classes:\n",
    "                self._save_results(False, [], [], [])\n",
    "                continue\n",
    "            self._save_results(True, ids, pred_classes, probs)\n",
    "\n",
    "        if not self._probs:\n",
    "            return torch.tensor([-1])\n",
    "\n",
    "        self.id_pos = [x.index(CATEGORY_NAME) for x in list(compress(self.pred_classes, self.is_ok))]\n",
    "        self._probs = pad_sequence(self._probs)\n",
    "        self._probs = torch.transpose(self._probs, 0, 1)\n",
    "        return self._probs\n",
    "\n",
    "    def get_probs(self):\n",
    "        return self.probs\n",
    "\n",
    "    def get_ids(self):\n",
    "        return self.ids\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.pred_classes\n",
    "\n",
    "    def get_category_id_pos(self):\n",
    "        return self.id_pos\n",
    "\n",
    "    def get_ok_list(self):\n",
    "        return self.is_ok\n",
    "\n",
    "    def is_backward_ready(self):\n",
    "        return False\n",
    "\n",
    "    def _extract_results(self, det):\n",
    "        det = det[:, 5:]\n",
    "        det = det[det[:, 0].argsort()]\n",
    "        det = torch.flip(det, [0])\n",
    "        ids = det[:, 1:].squeeze(1)\n",
    "        probs = det[:, :1].squeeze(1)\n",
    "        pred_classes = [self.classes[x] for x in ids.long().detach().cpu().numpy()]\n",
    "        return ids, probs, pred_classes\n",
    "\n",
    "    def _save_results(self, is_ok, ids, pred_classes, probs):\n",
    "        self.is_ok.append(is_ok)\n",
    "        self.ids.append(ids)\n",
    "        self.pred_classes.append(pred_classes)\n",
    "        self.probs.append(probs)\n",
    "        if is_ok:\n",
    "            self._probs.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from data.cocoapi_master.PythonAPI.pycocotools.coco import COCO\n",
    "from models.yolo.utils.datasets import pad_to_square, resize\n",
    "from models.yolo.utils.utils import load_classes\n",
    "\n",
    "ANNOTATION_FILEPATH = '/visinf/projects_students/shared_vqa/mscoco/coco-annotations/instances_train2014.json'\n",
    "DATASET_PATH = '/visinf/projects_students/shared_vqa/mscoco/train2014/'\n",
    "CLASS_PATH = \"models/yolo/data/coco.names\"\n",
    "IMG_SIZE = 416\n",
    "CATEGORY_NAME = 'person'\n",
    "\n",
    "class CocoYoloDataset(Dataset):\n",
    "    def __init__(self, device):\n",
    "        self.annotation_filepath = ANNOTATION_FILEPATH\n",
    "        self.dataset_path = DATASET_PATH\n",
    "        self.device = device\n",
    "\n",
    "        # initialize COCO api for instance annotations\n",
    "        self.coco=COCO(self.annotation_filepath)\n",
    "        self.imgIds = self.coco.getImgIds(catIds=[self._get_category_id(CATEGORY_NAME)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgIds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index == 10035: # The corresponding image is corrupted\n",
    "            index = 10034\n",
    "        img_id = self.imgIds[index]\n",
    "        img_infos = self.coco.loadImgs([img_id])[0]\n",
    "        filepath = self.dataset_path+img_infos['file_name']\n",
    "        img = Image.open(filepath)\n",
    "        if len(np.shape(img)) == 2:\n",
    "            img = img.convert('RGB')\n",
    "        gt = self._get_ground_truth(img=img, img_id=img_id, category_name=CATEGORY_NAME)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img, _ = pad_to_square(img, 0)\n",
    "        img = resize(img, IMG_SIZE)\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        return {\"img\": img, \"gt\": gt, \"filepath\": filepath}\n",
    "\n",
    "    def _get_ground_truth(self, img, img_id, category_name=\"\"):\n",
    "        ground_truth = np.zeros((np.shape(img)[0], np.shape(img)[1]))\n",
    "        contours = self._get_contours(img_id, category_name)\n",
    "        for contour in contours:\n",
    "            contour = contour.astype('int32')\n",
    "            cv2.fillPoly(ground_truth, [contour], 255)\n",
    "        ground_truth = cv2.resize(ground_truth, (IMG_SIZE, IMG_SIZE))\n",
    "        ground_truth = np.array(ground_truth, dtype=np.uint8)\n",
    "        ground_truth[ground_truth > 0] = 1\n",
    "        return ground_truth\n",
    "\n",
    "    def _get_contours(self, img_id, category_name):\n",
    "        if category_name == \"\":\n",
    "            annIds = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        else:\n",
    "            annIds = self.coco.getAnnIds(imgIds=[img_id], catIds=[self._get_category_id(category_name)])\n",
    "        anns = self.coco.loadAnns(annIds)\n",
    "        contours = []\n",
    "        for ann in anns:\n",
    "            if 'segmentation' in ann and type(ann['segmentation']) == list:\n",
    "                for seg in ann['segmentation']:\n",
    "                    contour = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "                    contours.append(contour)\n",
    "        return np.asarray(contours)\n",
    "\n",
    "    def _get_category_id(self, category_name):\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        for cat in cats:\n",
    "            if cat['name'] == category_name:\n",
    "                return cat['id']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import evaluate_grad_cam\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "dataset = CocoYoloDataset(device=DEVICE)\n",
    "model = YoloModel(device=DEVICE)\n",
    "\n",
    "evaluate_grad_cam.evaluate_dataset(model, dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}